{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HqF8p1rz-Sht"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VJMHV0xH-Vbg"
      },
      "outputs": [],
      "source": [
        "from conflict_lstm.latest_run import *\n",
        "from conflict_lstm.hpc_construct import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.enabled = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "veK5KTD6-yOL"
      },
      "source": [
        "## Functional form\n",
        "The wrapper function carries out most of the heavy lifting when we wish to train our models. We pass the structure argument (as detailed in the LSTMencdec docstrings) alongside the loss function and normalising averages calculated from our dataset. Here we modify the weights of a binary cross entropy loss function. The class weights, average, std and hdf5 dataset should be located in the local directory from which the script is run. Please note the example below is extracted from a script run on the HPC. It is not recommended to try to run this in an .ipynb notebook due to the overhead. For previously run scripts please see the results folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RkpzfetM-w4D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mzrk_ERp-PHw"
      },
      "outputs": [],
      "source": [
        "# defining the structure of the encoder decoder to be produced inside wrapper.\n",
        "# The structure wrapper outlines the number of channels of both the encoder and decoder model.\n",
        "# The structure argument is outlined by the number of channels in each list entry.\n",
        "# For the below structure a 0 entry denotes the absence of a layer, the non zero values encode the number of channels to convolute the dimensions of the input image into new\n",
        "# Data. for example, the first encoder has two layers, one with 12 channels, one with 24. The hidden state of the 24 layer channel is passed to the decoder, which has 24,12,6,5\n",
        "# Respectively\n",
        "\n",
        "structure = np.array([[12,24,0,0,0],[0,24,12,6,5]])\n",
        "\n",
        "# here we produce a weighted binary cross entropy loss function.\n",
        "d = np.load(\"weights_bce.npy\")\n",
        "weights = torch.tensor(d)\n",
        "weights = weights // 3\n",
        "weights = weights.to(device)\n",
        "b = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
        "\n",
        "# here we load in the average and standard deviation of out image sequence channels \n",
        "# for standard score normalisation\n",
        "avg = np.load(\"min_event_25_avg.npy\")\n",
        "std = np.load(\"min_event_25_std.npy\")\n",
        "\n",
        "# here we define which of our image channels need to be normalised (the channels which are not normalised are pre normlised by virtue of being categorical)\n",
        "apbln = [0,1,0,0,1]\n",
        "\n",
        "wrapper_full(\"bce_3\", 10, structure, b, avg, std, apbln, lr = 0.001, epochs = 2000, batch_size = 200)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Example_model_training.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
